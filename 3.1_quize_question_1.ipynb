{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [\"cat\", \"dog\", \"car\", \"bus\", \"ran\", \"fast\", \"the\", \"and\", \"sat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose that the vocabulary is {cat, dog, car, bus, ran, fast, the, and, sat}. There are two document classes, namely animal and vehicle. The training dataset of a text classification model consists of only three sentences, which include “the dog ran fast”, “the cat sat” and “the car and the bus ran fast”. The first two sentences are labeled animal and the last sentence is labeled vehicle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q1_a Draw count-based vector representations of all three sentences using bag-of-word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"the dog ran fast\"\n",
    "str2 = \"the cat sat\" \n",
    "str3 = \"the car and the bus ran fast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp\n",
    "# def tokenize(text):\n",
    "#     # Replace punctuation marks with space + punctuation\n",
    "#     punctuation_pattern = r'([.,!?;:])'\n",
    "#     text = re.sub(punctuation_pattern, r' \\1', text)\n",
    "#     print(text)\n",
    "#     return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return the string obtained by replacing the leftmost\n",
      "non-overlapping occurrences of the pattern in string by the\n",
      "replacement repl.  repl can be either a string or a callable;\n",
      "if a string, backslash escapes in it are processed.  If it is\n",
      "a callable, it's passed the Match object and must return\n",
      "a replacement string to be used.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/packages/miniforge3/envs/nlp/lib/python3.10/re.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "import re\n",
    "?re.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(string):\n",
    "    punctuation_pattern = r'([.,!?;:])'\n",
    "    string = re.sub(pattern=punctuation_pattern, repl=' ', string=string)\n",
    "    res = string.split()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dog', 'ran', 'fast']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countString(string, vocabulary):\n",
    "    string_dict = {}\n",
    "    string_list = tokenize(string)\n",
    "    # print(string_list)\n",
    "    for word in vocabulary:\n",
    "        if word in string_list:\n",
    "            # print(word)\n",
    "            if word in string_dict.keys():\n",
    "                string_dict[word] += 1\n",
    "            else:\n",
    "                string_dict[word] = 1\n",
    "        else: \n",
    "            string_dict[word] = 0\n",
    "    return string_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'car', 'bus', 'ran', 'fast', 'the', 'and', 'sat']\n",
      "the dog ran fast\n",
      "[0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
      "the cat sat\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "the car and the bus ran fast\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)\n",
    "feature_list = []\n",
    "for str in [str1, str2, str3]:\n",
    "    print(str)\n",
    "    str_dict = countString(string=str, vocabulary=vocabulary)\n",
    "    feature_list.append(list(str_dict.values()))\n",
    "    print(list(str_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q1_b  Manually cluster the training examples using 2-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 1 1 0 0]\n",
      " [1 0 0 0 0 0 1 0 1]\n",
      " [0 0 1 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature_array = np.array(feature_list)\n",
    "print(feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# k-means clustering\n",
    "import array\n",
    "from turtle import distance\n",
    "import numpy as np\n",
    "for i in range(1, 3):\n",
    "    print(i)\n",
    "def kMeansClustering(feature_array, k=2, max_iteration = 100):\n",
    "    # initiate centroid randomly\n",
    "    centroid = feature_array[np.random.choice(feature_array.shape[0],\n",
    "                                               k, replace=False)]\n",
    "    print(feature_array)\n",
    "    print(centroid)\n",
    "    lables = []\n",
    "    for i in range(max_iteration):\n",
    "        # TODO here\n",
    "        # calculate distance and assign cluster \n",
    "        distance = np.linalg.norm(feature_array[:, np.newaxis,:] - centroid,\n",
    "                                  axis = 2)\n",
    "        print(f\"distance: %\", distance)\n",
    "        labels = np.argmin(distance, axis=1)\n",
    "\n",
    "        # update centroid\n",
    "        new_centroid = np.array([feature_array[labels == m].mean(axis=0) \n",
    "                                  for m in range(k)]) \n",
    "        if np.allclose(new_centroid, centroid):\n",
    "            break\n",
    "        centroid = new_centroid\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 1 1 0 0]\n",
      " [1 0 0 0 0 0 1 0 1]\n",
      " [0 0 1 1 1 1 1 1 0]]\n",
      "[[1 0 0 0 0 0 1 0 1]\n",
      " [0 1 0 0 1 1 1 0 0]]\n",
      "distance: % [[2.23606798 0.        ]\n",
      " [0.         2.23606798]\n",
      " [2.64575131 2.        ]]\n",
      "distance: % [[2.23606798 1.        ]\n",
      " [0.         2.23606798]\n",
      " [2.64575131 1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(feature_array)\n",
    "# print(np.random.choice(feature_array.shape[0], 2, replace=False))\n",
    "kMeansClustering(feature_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
