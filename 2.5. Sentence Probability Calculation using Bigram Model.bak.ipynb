{"cells":[{"cell_type":"markdown","metadata":{"id":"eS1h8tqidd9I"},"source":["**Tasks**\n","\n","In Task 2, we successfully implemented N-gram models, which laid the groundwork for understanding how words and their sequences can be analyzed to predict and interpret language patterns. Building upon that foundational knowledge, this assignment focuses specifically on the application of a bigram (2-gram) model to calculate the probability of a given sentence.\n","\n","1.   Implement Bigram Model Construction: Calculate and store the probability of each bigram based on the provided corpus.\n","2.   Calculate the Probability of a Given Sentence: Use the constructed bigram model to calculate the probability of a specific sentence.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_MwuhaddMap"},"outputs":[],"source":["def tokenize(text):\n","    return text.lower().split()\n","\n","def padSequence(sequence_, ngram_, is_pad_left_ = True, is_pad_right_ = True,\n","                pad_left_token_ = \"<s>\", pad_right_token_ = \"</s>\"):\n","    assert isinstance(sequence_, list), \"sequence_ is not list\"\n","    if (is_pad_left_):\n","        i = 0\n","        while (i < ngram_ - 1):\n","            sequence_.insert(0, pad_left_token_)\n","            i += 1\n","    if (is_pad_right_):\n","        i = 0\n","        while (i < ngram_ - 1):\n","            sequence_.append(pad_right_token_)\n","            i += 1\n","    return sequence_\n","\n","def generate_ngrams(words, n):\n","    # TODO: Implement the logic to generate n-grams from the list of words\n","    words = padSequence(sequence_=words, ngram_=n)\n","    res = [tuple(words[i:i + n]) for i in range(len(words) - n + 1)]\n","    # res = dict(res)\n","    # res = {words[0]: words[1:] for word in words}\n","    return res\n","\n","def count_ngrams(ngrams):\n","    ngram_counts = {}\n","    for ngram in ngrams:\n","        if ngram in ngram_counts:\n","            ngram_counts[ngram] += 1\n","        else:\n","            ngram_counts[ngram] = 1\n","    return ngram_counts\n","\n","def calculate_ngram_probabilities(ngram_counts):\n","    total_ngrams = sum(ngram_counts.values())\n","    ngram_probabilities = {ngram: (count / total_ngrams) for ngram, count in ngram_counts.items()}\n","    return ngram_probabilities\n","\n","def query_ngram_probability(ngram, ngram_probabilities):\n","    return ngram_probabilities.get(ngram, 0)\n","\n","def build_bigram_model(corpus):\n","    \"\"\"\n","    TODO: Build the bigram model\n","    - Count the occurrences of each bigram\n","    - Calculate the probability of each bigram based on counts\n","    \"\"\"\n","    bigram_counts = {}\n","    unigram_counts = {}\n","    # Your code here to populate bigram_counts and unigram_counts\n","    words = tokenize(corpus)\n","    # pad_left_token = \"<s>\"\n","    # right_pad_token = \"</s>\"\n","    # words.insert(0, pad_left_token)\n","    # words.append(right_pad_token)\n","    # ngram = 2\n","    # bigram_counts = {words[i:i + ngram] for i in range(len(words) - ngram + 1)}\n","    # ngram = 1\n","    # unigram_counts = {words[i:i + ngram] for i in range(len(words) - ngram + 1)}\n","    bigram_tuples = generate_ngrams(words=words, n=2)\n","    bigrams = dict(bigram_tuples) \n","    bigram_counts = count_ngrams(bigrams)\n","    print(bigrams)\n","\n","    # Calculate bigram probabilities\n","    bigram_probabilities = {}\n","    # Your code here to calculate probabilities from counts\n","    # total_bigram_counts = len(bigram_counts.keys())\n","    # bigram_probabilities = {bigram: (count / total_bigram_counts) for bigram, count in bigram_counts.items()}\n","    bigram_probabilities = calculate_ngram_probabilities(bigram_counts)\n","    # unigram\n","    # unigrams = generate_ngrams(words=words, n = 1)\n","    # unigram_counts = count_ngrams(unigrams)\n","    print(zip(bigrams, bigram_counts, bigram_probabilities))\n","    return bigram_probabilities\n","\n","def build_unigram_model(corpus):\n","    unigram_counts = {}\n","    words = tokenize(corpus)\n","    # pad_left_token = \"<s>\"\n","    # right_pad_token = \"</s>\"\n","    # words.insert(0, pad_left_token)\n","    # words.append(right_pad_token)\n","    # ngram = 2\n","    # bigram_counts = {words[i:i + ngram] for i in range(len(words) - ngram + 1)}\n","    # ngram = 1\n","    # unigram_counts = {words[i:i + ngram] for i in range(len(words) - ngram + 1)}\n","    unigram_tuples = generate_ngrams(words=words, n=1)\n","    unigrams = dict(unigram_tuples) \n","    unigram_counts = count_ngrams(unigrams)\n","    print(unigrams)\n","\n","    # Calculate bigram probabilities\n","    unigram_probabilities = {}\n","    # Your code here to calculate probabilities from counts\n","    # total_bigram_counts = len(bigram_counts.keys())\n","    # bigram_probabilities = {bigram: (count / total_bigram_counts) for bigram, count in bigram_counts.items()}\n","    unigram_probabilities = calculate_ngram_probabilities(unigrams)\n","    # unigram\n","    # unigrams = generate_ngrams(words=words, n = 1)\n","    # unigram_counts = count_ngrams(unigrams)\n","    print(zip(unigrams, unigram_counts, unigram_probabilities))\n","    return unigram_probabilities\n","\n","def bigram_conditional_probilities(unigram_probabilities, bigram_probabilities):\n","    conditional_probabilities = {}\n","    for bigram in bigram_probabilities.keys():\n","        conditional_prob_rhs_lhs = bigram_probabilities.get(bigram, 1) / query_ngram_probability(bigram[0], 1)\n","        conditional_probabilities.update({bigram: conditional_prob_rhs_lhs})\n","    return conditional_probabilities\n","\n","    # unigram_probabilities.get\n","    # query_ngram_probability(unigram_probabilities)\n","    # bigram_counts = count_ngrams(bigrams)\n","    # for bigram in bigram_counts:\n","        # conditional_probabilitys = bigram_counts[bigram] / sum(bigram_counts[key])\n","\n","alpha = 1\n","def calculate_sentence_probability(sentence, bigram_probabilities):\n","    \"\"\"\n","    TODO: Calculate the probability of a sentence using the bigram model\n","    - Split the sentence into words\n","    - Calculate the probability of each bigram in the sentence and multiply them to get the sentence probability\n","    \"\"\"\n","    words = tokenize(sentence)\n","    words = padSequence(words, ngram_=2)\n","    bigram_tuples = generate_ngrams(words=words, n=2)\n","    bigrams = dict(bigram_tuples)\n","    probability = 1\n","    # Your code here to calculate the sentence probability\n","    bigram_probabilities = build_bigram_model(sentence)\n","    unigram_probabilities = build_unigram_model(sentence)\n","    conditional_probabilities = bigram_conditional_probilities(unigram_probabilities, bigram_conditional_probilities)\n","    for bigram in bigrams:\n","        probability *= conditional_probabilities[bigram]\n","        # word_probability = conditional_probabilities.get(bigram, alpha / (sum(unigram_counts.values()) + alpha * vocabulary_size))\n","    return probability\n","\n","# Example corpus\n","corpus = \"this is an example sentence for the corpus it is just an example\"\n","# Build the bigram model\n","bigram_probabilities = build_bigram_model(corpus)\n","\n","# Calculate the probability of a given sentence\n","sentence = \"this is an example\"\n","probability = calculate_sentence_probability(sentence, bigram_probabilities)\n","print(f\"Sentence Probability: {probability}\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1bH1vqaupc1r7uM_0Hd9FaBBM499ccMao","timestamp":1710553808038}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
