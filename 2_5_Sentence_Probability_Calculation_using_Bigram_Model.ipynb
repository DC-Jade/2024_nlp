{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DC-Jade/2024_nlp/blob/main/2_5_Sentence_Probability_Calculation_using_Bigram_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks**\n",
        "\n",
        "In Task 2, we successfully implemented N-gram models, which laid the groundwork for understanding how words and their sequences can be analyzed to predict and interpret language patterns. Building upon that foundational knowledge, this assignment focuses specifically on the application of a bigram (2-gram) model to calculate the probability of a given sentence.\n",
        "\n",
        "1.   Implement Bigram Model Construction: Calculate and store the probability of each bigram based on the provided corpus.\n",
        "2.   Calculate the Probability of a Given Sentence: Use the constructed bigram model to calculate the probability of a specific sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "eS1h8tqidd9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_MwuhaddMap"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def build_bigram_model(corpus):\n",
        "    \"\"\"\n",
        "    TODO: Build the bigram model\n",
        "    - Count the occurrences of each bigram\n",
        "    - Calculate the probability of each bigram based on counts\n",
        "    \"\"\"\n",
        "    bigram_counts = {}\n",
        "    unigram_counts = {}\n",
        "    # Your code here to populate bigram_counts and unigram_counts\n",
        "\n",
        "    # Calculate bigram probabilities\n",
        "    bigram_probabilities = {}\n",
        "    # Your code here to calculate probabilities from counts\n",
        "\n",
        "    return bigram_probabilities\n",
        "\n",
        "def calculate_sentence_probability(sentence, bigram_probabilities):\n",
        "    \"\"\"\n",
        "    TODO: Calculate the probability of a sentence using the bigram model\n",
        "    - Split the sentence into words\n",
        "    - Calculate the probability of each bigram in the sentence and multiply them to get the sentence probability\n",
        "    \"\"\"\n",
        "    words = tokenize(sentence)\n",
        "    probability = 1\n",
        "    # Your code here to calculate the sentence probability\n",
        "\n",
        "    return probability\n",
        "\n",
        "# Example corpus\n",
        "corpus = \"this is an example sentence for the corpus it is just an example\"\n",
        "# Build the bigram model\n",
        "bigram_probabilities = build_bigram_model(corpus)\n",
        "\n",
        "# Calculate the probability of a given sentence\n",
        "sentence = \"this is an example\"\n",
        "probability = calculate_sentence_probability(sentence, bigram_probabilities)\n",
        "print(f\"Sentence Probability: {probability}\")\n"
      ]
    }
  ]
}